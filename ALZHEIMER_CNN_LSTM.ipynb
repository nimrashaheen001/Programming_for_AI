{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDLagOrPiViWpcJGBMB0YN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimrashaheen001/Programming_for_AI/blob/main/ALZHEIMER_CNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UjZcf3TGIZfc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.svm import SVC  # Import Support Vector Machine\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, TimeDistributed, Reshape\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the path to the dataset folder\n",
        "dataset_path = '/content/drive/MyDrive/archive1'  # Replace with your actual folder path\n",
        "\n",
        "# Verify the folder structure by listing files\n",
        "import os\n",
        "print(\"Dataset folders:\", os.listdir(dataset_path))  # Should show 'train' and 'test' folders\n",
        "\n",
        "# Paths to train and test folders\n",
        "train_path = os.path.join(dataset_path, 'train')\n",
        "test_path = os.path.join(dataset_path, 'test')\n",
        "\n",
        "# Verify train and test folders\n",
        "print(\"Train folder contents:\", os.listdir(train_path))\n",
        "print(\"Test folder contents:\", os.listdir(test_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9TBwWl_IeNV",
        "outputId": "fea1b1d2-9d76-4171-d39e-77ddefcb60a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset folders: ['train', 'test']\n",
            "Train folder contents: ['NonDemented', 'Demented']\n",
            "Test folder contents: ['Demented', 'NonDemented']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define image dimensions and batch size\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation setup for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,           # Normalize pixel values to [0, 1]\n",
        "    rotation_range=30,           # Random rotation up to 30 degrees\n",
        "    width_shift_range=0.2,       # Horizontal shift\n",
        "    height_shift_range=0.2,      # Vertical shift\n",
        "    shear_range=0.2,             # Shear transformation\n",
        "    zoom_range=0.2,              # Random zoom\n",
        "    horizontal_flip=True,        # Flip images horizontally\n",
        "    fill_mode='nearest'          # Fill missing pixels after transformation\n",
        ")\n",
        "\n",
        "# Data generator for the test set (without augmentation)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "# Load and preprocess training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,                   # Use the train folder path\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',          # For binary classification\n",
        "    color_mode='rgb',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Load and preprocess testing data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,                    # Use the test folder path\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    color_mode='rgb',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e00wA_sIeJ1",
        "outputId": "274b979d-f800-4ed9-8894-66ef03d50e89"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4861 images belonging to 2 classes.\n",
            "Found 1603 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "# Import the Rescaling layer correctly\n",
        "from tensorflow.keras.layers import Rescaling  # Or tf.keras.layers.experimental.preprocessing.Rescaling for older versions\n",
        "\n",
        "# ... rest of your code ..."
      ],
      "metadata": {
        "id": "jJQlCTRvIeHK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Flatten"
      ],
      "metadata": {
        "id": "P8HT1oPCIeEQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN-LSTM Architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Define input shape: 1 time step, 128x128 image with 3 channels\n",
        "input_shape = (1, 128, 128, 3)\n",
        "\n",
        "# TimeDistributed Conv2D Layer 1\n",
        "model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal'), input_shape=input_shape))\n",
        "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
        "\n",
        "# TimeDistributed Conv2D Layer 2\n",
        "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal')))\n",
        "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
        "\n",
        "# Flatten the output of CNN layers\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "# Reshape to LSTM-compatible shape\n",
        "model.add(Reshape((1, -1)))  # Reshape to (time_steps, features)\n",
        "\n",
        "# LSTM Layer\n",
        "model.add(LSTM(100, activation='tanh'))\n",
        "\n",
        "# Dense Layer (Output)\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)  # Learning rate 0.0001\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the Model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=25,  # Changed to 100 epochs\n",
        "    validation_data=test_generator,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Step 5: Save the Trained Model\n",
        "model.save('/content/drive/MyDrive/alzheimers_cnn_model.h5')\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "n1XvVK5zIeBd",
        "outputId": "8d36ffe1-d225-426b-c59d-046b3ed23eba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 224, 224, 3), dtype=float32). Expected shape (None, 1, 128, 128, 3), but input has incompatible shape (None, 224, 224, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 224, 224, 3), dtype=float32)\n  • training=True\n  • mask=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4a15137145b3>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Step 4: Train the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Changed to 100 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m_adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0madjusted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0;34mf\"Invalid input shape for input {x}. Expected shape \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;34mf\"{ref_shape}, but input has incompatible shape {x.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 224, 224, 3), dtype=float32). Expected shape (None, 1, 128, 128, 3), but input has incompatible shape (None, 224, 224, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 224, 224, 3), dtype=float32)\n  • training=True\n  • mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3u3dmLPeId-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fLFCzkZ9Id7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uZntqtfhId4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EHP8aGTvId1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lbB2In2YIdyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qTElGC35IdvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AlZiF9IOIdsH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}