{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNFs8GQWHGByfSLKUVeTmUE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimrashaheen001/Programming_for_AI/blob/main/BasepaperImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhOF-ZCumbr-",
        "outputId": "6515931b-49ad-4b17-ae64-2e705a76caf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nibabel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.12.2)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6400 images in total.\n",
            "Calling __len__ function!\n",
            "Epoch 0/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [04:45<00:00,  4.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 10.8677 Acc: 0.4854 MMSE Loss: 19.0536 CDR Loss: 0.4276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [01:06<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 8.3758 Acc: 0.5438 MMSE Loss: 14.5230 CDR Loss: 0.3276\n",
            "Epoch 1/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 9.8764 Acc: 0.4955 MMSE Loss: 17.1688 CDR Loss: 0.4098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 17.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 9.1959 Acc: 0.5195 MMSE Loss: 15.4099 CDR Loss: 0.3628\n",
            "Epoch 2/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 9.5573 Acc: 0.5115 MMSE Loss: 16.5912 CDR Loss: 0.4070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 8.1571 Acc: 0.5539 MMSE Loss: 14.1137 CDR Loss: 0.3780\n",
            "Epoch 3/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:28<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 9.3156 Acc: 0.5199 MMSE Loss: 16.1708 CDR Loss: 0.3822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 8.2580 Acc: 0.5547 MMSE Loss: 14.3374 CDR Loss: 0.3220\n",
            "Epoch 4/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 9.1210 Acc: 0.5180 MMSE Loss: 15.8462 CDR Loss: 0.3906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 8.3710 Acc: 0.5141 MMSE Loss: 14.4666 CDR Loss: 0.3613\n",
            "Epoch 5/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 9.1940 Acc: 0.5170 MMSE Loss: 15.9758 CDR Loss: 0.3956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 9.5478 Acc: 0.5734 MMSE Loss: 16.8320 CDR Loss: 0.3123\n",
            "Epoch 6/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 8.8529 Acc: 0.5320 MMSE Loss: 15.3409 CDR Loss: 0.3883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 11.0605 Acc: 0.5734 MMSE Loss: 19.9656 CDR Loss: 0.3798\n",
            "Epoch 7/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 8.0100 Acc: 0.5555 MMSE Loss: 13.8578 CDR Loss: 0.3244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 8.0343 Acc: 0.5922 MMSE Loss: 13.9963 CDR Loss: 0.3287\n",
            "Epoch 8/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 7.7802 Acc: 0.5641 MMSE Loss: 13.4033 CDR Loss: 0.3364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 10.2897 Acc: 0.5672 MMSE Loss: 18.4394 CDR Loss: 0.3537\n",
            "Epoch 9/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 7.5550 Acc: 0.5670 MMSE Loss: 12.9485 CDR Loss: 0.3513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 10.2087 Acc: 0.5953 MMSE Loss: 18.3982 CDR Loss: 0.3160\n",
            "Epoch 10/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 7.4164 Acc: 0.5736 MMSE Loss: 12.7149 CDR Loss: 0.3274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 7.3784 Acc: 0.5914 MMSE Loss: 12.7335 CDR Loss: 0.3136\n",
            "Epoch 11/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 7.1266 Acc: 0.5748 MMSE Loss: 12.1545 CDR Loss: 0.3274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 16.7154 Acc: 0.5859 MMSE Loss: 31.3014 CDR Loss: 0.3158\n",
            "Epoch 12/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 7.0439 Acc: 0.5938 MMSE Loss: 12.0173 CDR Loss: 0.3209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 6.7891 Acc: 0.5898 MMSE Loss: 11.5489 CDR Loss: 0.3105\n",
            "Epoch 13/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 6.9188 Acc: 0.5979 MMSE Loss: 11.7742 CDR Loss: 0.3271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 6.9563 Acc: 0.6109 MMSE Loss: 11.9811 CDR Loss: 0.3041\n",
            "Epoch 14/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:28<00:00,  6.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 6.5515 Acc: 0.6059 MMSE Loss: 11.1080 CDR Loss: 0.3081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 6.6122 Acc: 0.6141 MMSE Loss: 11.3066 CDR Loss: 0.2938\n",
            "Epoch 15/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 6.4516 Acc: 0.6146 MMSE Loss: 10.9140 CDR Loss: 0.3117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 6.7326 Acc: 0.6125 MMSE Loss: 11.5481 CDR Loss: 0.2996\n",
            "Epoch 16/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 6.5369 Acc: 0.6098 MMSE Loss: 11.0872 CDR Loss: 0.3057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 6.4218 Acc: 0.6148 MMSE Loss: 10.9425 CDR Loss: 0.2929\n",
            "Epoch 17/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:28<00:00,  6.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 6.3379 Acc: 0.6158 MMSE Loss: 10.7248 CDR Loss: 0.2936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 7.1625 Acc: 0.6195 MMSE Loss: 12.4386 CDR Loss: 0.2834\n",
            "Epoch 18/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:28<00:00,  6.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 6.3577 Acc: 0.6215 MMSE Loss: 10.7445 CDR Loss: 0.3103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 6.5805 Acc: 0.6141 MMSE Loss: 11.2610 CDR Loss: 0.3020\n",
            "Epoch 19/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 6.3144 Acc: 0.6213 MMSE Loss: 10.6665 CDR Loss: 0.3042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 6.5938 Acc: 0.6078 MMSE Loss: 11.2772 CDR Loss: 0.2830\n",
            "Epoch 20/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:28<00:00,  6.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 6.2600 Acc: 0.6244 MMSE Loss: 10.5832 CDR Loss: 0.2980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 6.7695 Acc: 0.6234 MMSE Loss: 11.6220 CDR Loss: 0.2972\n",
            "Epoch 21/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 6.3265 Acc: 0.6215 MMSE Loss: 10.7187 CDR Loss: 0.3011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 6.4332 Acc: 0.6227 MMSE Loss: 10.9774 CDR Loss: 0.3001\n",
            "Epoch 22/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:28<00:00,  6.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 6.1509 Acc: 0.6162 MMSE Loss: 10.3386 CDR Loss: 0.3072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 6.4792 Acc: 0.6203 MMSE Loss: 11.0903 CDR Loss: 0.2797\n",
            "Epoch 23/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:29<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 6.2713 Acc: 0.6258 MMSE Loss: 10.6065 CDR Loss: 0.2952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 6.3210 Acc: 0.6281 MMSE Loss: 10.7665 CDR Loss: 0.2865\n",
            "Epoch 24/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [03:28<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 6.3565 Acc: 0.6256 MMSE Loss: 10.7592 CDR Loss: 0.3074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 320/320 [00:17<00:00, 18.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 6.6636 Acc: 0.6203 MMSE Loss: 11.4279 CDR Loss: 0.3124\n",
            "Best val Acc: 0.628125\n",
            "Training complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install nibabel\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "import nibabel as nib  # For potential metadata extraction (if needed)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from PIL import Image  # For image loading\n",
        "from torchvision import transforms # For image transformations\n",
        "#Mount Google Drive (uncomment this in Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class BasicBlock2D(nn.Module):  # Changed class name to BasicBlock2D\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock2D, self).__init__()\n",
        "        # Changed to 2D convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        # Changed to 2D batch normalization\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet2D(nn.Module):  # Changed class name to ResNet2D\n",
        "    def __init__(self, block, num_blocks, in_channels=3, num_classes=4):  # Updated in_channels and num_classes\n",
        "        super(ResNet2D, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        # Initial convolution layer (changed to 2D)\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)  # Changed to 2D batch normalization\n",
        "\n",
        "        # ResNet layers (using BasicBlock2D)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "\n",
        "        # Classification head (changed to 2D)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Changed to 2D adaptive average pooling\n",
        "        self.fc = nn.Linear(512 * block.expansion, 512)\n",
        "\n",
        "        # Multiple output heads (adjusted for 4 classes)\n",
        "        self.classification_head = nn.Linear(512, num_classes)\n",
        "        self.regression_mmse = nn.Linear(512, 1)  # MMSE score regression\n",
        "        self.regression_cdr = nn.Linear(512, 1)   # Clinical Dementia Rating regression\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input processing\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        # ResNet blocks\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "\n",
        "        # Global pooling\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        # Shared features\n",
        "        features = F.relu(self.fc(out))\n",
        "\n",
        "        # Multi-task outputs\n",
        "        classification = self.classification_head(features)\n",
        "        mmse_score = self.regression_mmse(features)\n",
        "        cdr_score = self.regression_cdr(features)\n",
        "\n",
        "        return {\n",
        "            'classification': classification,\n",
        "            'mmse_score': mmse_score,\n",
        "            'cdr_score': cdr_score,\n",
        "            'features': features\n",
        "        }\n",
        "\n",
        "def ResNet18_2D(in_channels=3, num_classes=4):  # Changed function name and defaults\n",
        "    return ResNet2D(BasicBlock2D, [2, 2, 2, 2], in_channels, num_classes)  # Us\n",
        "\n",
        "class BrainMRIDataset(Dataset):\n",
        "    def __init__(self, data_dir, classes=['VeryMildDemented', 'MildDemented', 'NonDemented', 'ModerateDemented'], transform=None):\n",
        "        \"\"\"\n",
        "        Dataset for multimodal brain MRI data\n",
        "\n",
        "        Args:\n",
        "            data_dir (str): Directory containing the data\n",
        "            classes (list): List of class names\n",
        "            transform (callable, optional): Optional transform to be applied on a sample\n",
        "        \"\"\"\n",
        "        self.data_dir = data_dir\n",
        "        self.classes = classes\n",
        "        self.transform = transform\n",
        "\n",
        "        # Find all images and labels\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Assuming directory structure: data_dir/class_label/image.png (or other image format)\n",
        "        for class_idx, class_name in enumerate(classes):\n",
        "            class_path = os.path.join(data_dir, class_name)\n",
        "            image_files = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
        "\n",
        "            for image_file in image_files:\n",
        "                image_path = os.path.join(class_path, image_file)\n",
        "                self.images.append(image_path)\n",
        "                self.labels.append(class_idx) # Assign class index as label\n",
        "\n",
        "        print(f\"Found {len(self.images)} images in total.\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(image_path).convert('RGB')  # Convert to RGB if needed\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Simulate or load mmse_score and cdr_score (Replace with your actual logic)\n",
        "        # Here I'm simulating them based on the label for demonstration purposes\n",
        "        mmse_score = torch.tensor([28.0 if label == 2 else 20.0 + np.random.normal(0, 2)], dtype=torch.float32) # Assuming label 2 is 'NonDemented'\n",
        "        cdr_score = torch.tensor([0.0 if label == 2 else 1.0 + np.random.normal(0, 0.5)], dtype=torch.float32)   # Assuming label 2 is 'NonDemented'\n",
        "\n",
        "\n",
        "        return {'image': image, 'label': torch.tensor(label, dtype=torch.long), 'mmse_score': mmse_score, 'cdr_score': cdr_score}\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        print(\"Calling __len__ function!\")  # Debug print statement\n",
        "        return len(self.images)\n",
        "\n",
        "# ... (Rest of the code) ...\n",
        "\n",
        "def train_model(model, dataloaders, criterion_dict, optimizer, scheduler, num_epochs=25, device='cuda'):\n",
        "    model = model.to(device)\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            running_mmse_loss = 0.0\n",
        "            running_cdr_loss = 0.0\n",
        "\n",
        "            # Iterate over data\n",
        "            for inputs in tqdm(dataloaders[phase]):\n",
        "                images = inputs['image'].to(device)\n",
        "                labels = inputs['label'].to(device)\n",
        "                mmse_scores = inputs['mmse_score'].to(device)\n",
        "                cdr_scores = inputs['cdr_score'].to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(images)\n",
        "                    _, preds = torch.max(outputs['classification'], 1)\n",
        "\n",
        "                    # Compute losses\n",
        "                    classification_loss = criterion_dict['classification'](outputs['classification'], labels)\n",
        "                    mmse_loss = criterion_dict['regression'](outputs['mmse_score'], mmse_scores)\n",
        "                    cdr_loss = criterion_dict['regression'](outputs['cdr_score'], cdr_scores)\n",
        "\n",
        "                    # Combined loss\n",
        "                    loss = classification_loss + 0.5 * mmse_loss + 0.5 * cdr_loss\n",
        "\n",
        "                    # Backward + optimize only in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * images.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                running_mmse_loss += mmse_loss.item() * images.size(0)\n",
        "                running_cdr_loss += cdr_loss.item() * images.size(0)\n",
        "\n",
        "            if phase == 'train' and scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            epoch_mmse_loss = running_mmse_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_cdr_loss = running_cdr_loss / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} MMSE Loss: {epoch_mmse_loss:.4f} CDR Loss: {epoch_cdr_loss:.4f}')\n",
        "\n",
        "            # Deep copy the model if it's the best validation accuracy so far\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = model.state_dict().copy()\n",
        "\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "def main():\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        " # Set paths\n",
        "    data_dir = \"/content/drive/MyDrive/Alzheimer_MRI_4_classes_dataset\"  # Update with your Google Drive path\n",
        "\n",
        "    # Define transformations (resize, normalize, etc.)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize to a common size\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
        "    ])\n",
        "\n",
        "    # Create dataset\n",
        "    # Create dataset\n",
        "    dataset = BrainMRIDataset(data_dir=data_dir, classes=['VeryMildDemented', 'MildDemented', 'NonDemented', 'ModerateDemented'], transform=transform)\n",
        "    # Split into train and validation sets\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        range(len(dataset)),\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=dataset.labels\n",
        "    )\n",
        "\n",
        "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "    val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
        "\n",
        "    dataloaders = {\n",
        "        'train': train_loader,\n",
        "        'val': val_loader\n",
        "    }\n",
        "\n",
        "   # Create model\n",
        "    model = ResNet18_2D(in_channels=3, num_classes=4)  # Update in_channels and num_classes for 2D images and 4 classes\n",
        "    # ... (Loss, optimizer, training, saving - Similar a\n",
        "\n",
        "    # Define loss functions\n",
        "    criterion_dict = {\n",
        "        'classification': nn.CrossEntropyLoss(),\n",
        "        'regression': nn.MSELoss()\n",
        "    }\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "    # Train model\n",
        "    model = train_model(\n",
        "        model=model,\n",
        "        dataloaders=dataloaders,\n",
        "        criterion_dict=criterion_dict,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        num_epochs=25,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), 'brain_mri_model.pth')\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "def predict(model, dataloader, device='cuda'):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    results = {\n",
        "        'subject_ids': [],\n",
        "        'true_labels': [],\n",
        "        'predictions': [],\n",
        "        'mmse_scores': [],\n",
        "        'cdr_scores': []\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs in tqdm(dataloader):\n",
        "            images = inputs['image'].to(device)\n",
        "            labels = inputs['label'].cpu().numpy()\n",
        "            subject_ids = inputs['subject_id']\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs['classification'], 1)\n",
        "\n",
        "            # Store results\n",
        "            results['subject_ids'].extend(subject_ids)\n",
        "            results['true_labels'].extend(labels)\n",
        "            results['predictions'].extend(preds.cpu().numpy())\n",
        "            results['mmse_scores'].extend(outputs['mmse_score'].cpu().numpy().flatten())\n",
        "            results['cdr_scores'].extend(outputs['cdr_score'].cpu().numpy().flatten())\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JEWw2pqp4bHA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}