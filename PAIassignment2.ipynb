{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMR79kbjqQPZX/cJ/IPkJV6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimrashaheen001/Programming_for_AI/blob/main/PAIassignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3XnKixhVkoX1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "00hrqZe7k__l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the path to the dataset folder\n",
        "dataset_path = '/content/drive/MyDrive/archive1'  # Replace with your actual folder path\n",
        "\n",
        "# Verify the folder structure by listing files\n",
        "import os\n",
        "print(\"Dataset folders:\", os.listdir(dataset_path))  # Should show 'train' and 'test' folders\n",
        "\n",
        "# Paths to train and test folders\n",
        "train_path = os.path.join(dataset_path, 'train')\n",
        "test_path = os.path.join(dataset_path, 'test')\n",
        "\n",
        "# Verify train and test folders\n",
        "print(\"Train folder contents:\", os.listdir(train_path))\n",
        "print(\"Test folder contents:\", os.listdir(test_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS_-7gBPk_qC",
        "outputId": "90401533-c497-4c46-96a5-90d72caa7e0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset folders: ['train', 'test']\n",
            "Train folder contents: ['NonDemented', 'Demented']\n",
            "Test folder contents: ['Demented', 'NonDemented']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i5gjuol8lBa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define image dimensions and batch size\n",
        "image_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation setup for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,           # Normalize pixel values to [0, 1]\n",
        "    rotation_range=30,           # Random rotation up to 30 degrees\n",
        "    width_shift_range=0.2,       # Horizontal shift\n",
        "    height_shift_range=0.2,      # Vertical shift\n",
        "    shear_range=0.2,             # Shear transformation\n",
        "    zoom_range=0.2,              # Random zoom\n",
        "    horizontal_flip=True,        # Flip images horizontally\n",
        "    fill_mode='nearest'          # Fill missing pixels after transformation\n",
        ")\n",
        "\n",
        "# Data generator for the test set (without augmentation)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Load and preprocess training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,                   # Use the train folder path\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',          # For binary classification\n",
        "    color_mode='rgb',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Load and preprocess testing data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,                    # Use the test folder path\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    color_mode='rgb',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6h5C_q9k_IJ",
        "outputId": "a81fe57c-622d-41e2-d666-c497f6a88c19"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4861 images belonging to 2 classes.\n",
            "Found 1603 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "# Import the Rescaling layer correctly\n",
        "from tensorflow.keras.layers import Rescaling  # Or tf.keras.layers.experimental.preprocessing.Rescaling for older versions\n",
        "\n",
        "# ... rest of your code ..."
      ],
      "metadata": {
        "id": "fiPoV8wXBbbw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FaGvapijlkzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define the CNN Model Architecture\n",
        "model = Sequential([\n",
        "    # Input Layer with Rescaling\n",
        "    Rescaling(1.0 / 255, input_shape=(128, 128, 3)),\n",
        "\n",
        "    # First Convolutional Block\n",
        "    Conv2D(16, (3, 3), activation='relu'),                  # Conv2D with 16 filters\n",
        "    MaxPooling2D(pool_size=(2, 2)),                         # MaxPooling with pool size 2x2\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    Conv2D(32, (3, 3), activation='relu'),                  # Conv2D with 32 filters\n",
        "    MaxPooling2D(pool_size=(2, 2)),                         # MaxPooling with pool size 2x2\n",
        "    Dropout(0.2),                                           # Dropout with 0.2 rate\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    Conv2D(64, (3, 3), activation='relu'),                  # Conv2D with 64 filters\n",
        "    MaxPooling2D(pool_size=(2, 2)),                         # MaxPooling with pool size 2x2\n",
        "    Dropout(0.25),                                          # Dropout with 0.25 rate\n",
        "\n",
        "    # Flatten Layer\n",
        "    Flatten(),                                              # Flatten to convert feature maps to a vector\n",
        "\n",
        "    # Fully Connected Dense Layers\n",
        "    Dense(128, activation='relu'),                          # Dense layer with 128 units\n",
        "    Dense(64, activation='relu'),                           # Dense layer with 64 units\n",
        "\n",
        "    # Output Layer for Binary Classification\n",
        "    Dense(1, activation='sigmoid')                          # Output layer with 1 unit and sigmoid activation\n",
        "])\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Step 4: Train the Model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,  # Changed to 100 epochs\n",
        "    validation_data=test_generator,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Step 5: Save the Trained Model\n",
        "model.save('/content/drive/MyDrive/alzheimers_cnn_model.h5')\n",
        "\n",
        "# Print Model Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Si4fw-xek-6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c12cfa48-9bf1-4fff-85f0-db2fda8b4ea2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 2s/step - accuracy: 0.4874 - loss: 0.6932 - val_accuracy: 0.5022 - val_loss: 0.6931\n",
            "Epoch 2/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 776ms/step - accuracy: 0.5018 - loss: 0.6932 - val_accuracy: 0.5022 - val_loss: 0.6931\n",
            "Epoch 3/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 771ms/step - accuracy: 0.4897 - loss: 0.6932 - val_accuracy: 0.4978 - val_loss: 0.6931\n",
            "Epoch 4/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 766ms/step - accuracy: 0.4802 - loss: 0.6932 - val_accuracy: 0.4978 - val_loss: 0.6931\n",
            "Epoch 5/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 843ms/step - accuracy: 0.5029 - loss: 0.6932 - val_accuracy: 0.4978 - val_loss: 0.6932\n",
            "Epoch 6/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 790ms/step - accuracy: 0.5038 - loss: 0.6932 - val_accuracy: 0.4978 - val_loss: 0.6931\n",
            "Epoch 7/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 775ms/step - accuracy: 0.4893 - loss: 0.6932 - val_accuracy: 0.5022 - val_loss: 0.6931\n",
            "Epoch 8/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 792ms/step - accuracy: 0.5232 - loss: 0.6933 - val_accuracy: 0.5602 - val_loss: 0.6927\n",
            "Epoch 9/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 787ms/step - accuracy: 0.5332 - loss: 0.6927 - val_accuracy: 0.4978 - val_loss: 0.6930\n",
            "Epoch 10/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 792ms/step - accuracy: 0.5121 - loss: 0.6924 - val_accuracy: 0.5328 - val_loss: 0.6900\n",
            "Epoch 11/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 780ms/step - accuracy: 0.5480 - loss: 0.6876 - val_accuracy: 0.5727 - val_loss: 0.6737\n",
            "Epoch 12/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 786ms/step - accuracy: 0.6039 - loss: 0.6677 - val_accuracy: 0.5733 - val_loss: 0.6571\n",
            "Epoch 13/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 775ms/step - accuracy: 0.6436 - loss: 0.6416 - val_accuracy: 0.5883 - val_loss: 0.6509\n",
            "Epoch 14/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 993ms/step - accuracy: 0.6430 - loss: 0.6391 - val_accuracy: 0.5671 - val_loss: 0.6641\n",
            "Epoch 15/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 783ms/step - accuracy: 0.6336 - loss: 0.6391 - val_accuracy: 0.6363 - val_loss: 0.6434\n",
            "Epoch 16/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 853ms/step - accuracy: 0.6413 - loss: 0.6328 - val_accuracy: 0.5677 - val_loss: 0.6760\n",
            "Epoch 17/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 790ms/step - accuracy: 0.6451 - loss: 0.6291 - val_accuracy: 0.5689 - val_loss: 0.6896\n",
            "Epoch 18/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 783ms/step - accuracy: 0.6248 - loss: 0.6454 - val_accuracy: 0.6388 - val_loss: 0.6521\n",
            "Epoch 19/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 835ms/step - accuracy: 0.6368 - loss: 0.6305 - val_accuracy: 0.5683 - val_loss: 0.7007\n",
            "Epoch 20/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 831ms/step - accuracy: 0.6394 - loss: 0.6358 - val_accuracy: 0.6039 - val_loss: 0.6416\n",
            "Epoch 21/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 778ms/step - accuracy: 0.6512 - loss: 0.6280 - val_accuracy: 0.6438 - val_loss: 0.6351\n",
            "Epoch 22/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 755ms/step - accuracy: 0.6515 - loss: 0.6291 - val_accuracy: 0.6394 - val_loss: 0.6396\n",
            "Epoch 23/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 777ms/step - accuracy: 0.6379 - loss: 0.6361 - val_accuracy: 0.6382 - val_loss: 0.6367\n",
            "Epoch 24/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 785ms/step - accuracy: 0.6549 - loss: 0.6245 - val_accuracy: 0.6394 - val_loss: 0.6332\n",
            "Epoch 25/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 833ms/step - accuracy: 0.6337 - loss: 0.6337 - val_accuracy: 0.6432 - val_loss: 0.6340\n",
            "Epoch 26/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 788ms/step - accuracy: 0.6595 - loss: 0.6242 - val_accuracy: 0.6450 - val_loss: 0.6331\n",
            "Epoch 27/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 767ms/step - accuracy: 0.6391 - loss: 0.6306 - val_accuracy: 0.6020 - val_loss: 0.6442\n",
            "Epoch 28/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 781ms/step - accuracy: 0.6412 - loss: 0.6314 - val_accuracy: 0.6213 - val_loss: 0.6354\n",
            "Epoch 29/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 785ms/step - accuracy: 0.6527 - loss: 0.6202 - val_accuracy: 0.6463 - val_loss: 0.6315\n",
            "Epoch 30/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 755ms/step - accuracy: 0.6486 - loss: 0.6189 - val_accuracy: 0.5895 - val_loss: 0.6569\n",
            "Epoch 31/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 833ms/step - accuracy: 0.6380 - loss: 0.6251 - val_accuracy: 0.6220 - val_loss: 0.6342\n",
            "Epoch 32/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 784ms/step - accuracy: 0.6712 - loss: 0.6104 - val_accuracy: 0.5995 - val_loss: 0.6483\n",
            "Epoch 33/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 760ms/step - accuracy: 0.6559 - loss: 0.6238 - val_accuracy: 0.6419 - val_loss: 0.6299\n",
            "Epoch 34/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 814ms/step - accuracy: 0.6615 - loss: 0.6207 - val_accuracy: 0.6220 - val_loss: 0.6325\n",
            "Epoch 35/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 775ms/step - accuracy: 0.6491 - loss: 0.6237 - val_accuracy: 0.6220 - val_loss: 0.6335\n",
            "Epoch 36/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 755ms/step - accuracy: 0.6422 - loss: 0.6253 - val_accuracy: 0.6157 - val_loss: 0.6355\n",
            "Epoch 37/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 773ms/step - accuracy: 0.6672 - loss: 0.6157 - val_accuracy: 0.6475 - val_loss: 0.6259\n",
            "Epoch 38/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 786ms/step - accuracy: 0.6561 - loss: 0.6237 - val_accuracy: 0.6076 - val_loss: 0.6457\n",
            "Epoch 39/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 764ms/step - accuracy: 0.6396 - loss: 0.6297 - val_accuracy: 0.6301 - val_loss: 0.6303\n",
            "Epoch 40/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 771ms/step - accuracy: 0.6624 - loss: 0.6189 - val_accuracy: 0.6563 - val_loss: 0.6214\n",
            "Epoch 41/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 772ms/step - accuracy: 0.6617 - loss: 0.6180 - val_accuracy: 0.6575 - val_loss: 0.6213\n",
            "Epoch 42/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 777ms/step - accuracy: 0.6653 - loss: 0.6205 - val_accuracy: 0.5814 - val_loss: 0.6637\n",
            "Epoch 43/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 762ms/step - accuracy: 0.6548 - loss: 0.6113 - val_accuracy: 0.6507 - val_loss: 0.6235\n",
            "Epoch 44/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 847ms/step - accuracy: 0.6647 - loss: 0.6178 - val_accuracy: 0.6500 - val_loss: 0.6244\n",
            "Epoch 45/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 792ms/step - accuracy: 0.6559 - loss: 0.6212 - val_accuracy: 0.6538 - val_loss: 0.6192\n",
            "Epoch 46/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 765ms/step - accuracy: 0.6545 - loss: 0.6252 - val_accuracy: 0.6126 - val_loss: 0.6418\n",
            "Epoch 47/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 779ms/step - accuracy: 0.6588 - loss: 0.6212 - val_accuracy: 0.6488 - val_loss: 0.6243\n",
            "Epoch 48/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 789ms/step - accuracy: 0.6581 - loss: 0.6223 - val_accuracy: 0.6532 - val_loss: 0.6194\n",
            "Epoch 49/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 782ms/step - accuracy: 0.6622 - loss: 0.6129 - val_accuracy: 0.6519 - val_loss: 0.6206\n",
            "Epoch 50/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 786ms/step - accuracy: 0.6639 - loss: 0.6098 - val_accuracy: 0.6550 - val_loss: 0.6180\n",
            "Epoch 51/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 768ms/step - accuracy: 0.6515 - loss: 0.6223 - val_accuracy: 0.6500 - val_loss: 0.6208\n",
            "Epoch 52/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 780ms/step - accuracy: 0.6740 - loss: 0.6089 - val_accuracy: 0.6338 - val_loss: 0.6414\n",
            "Epoch 53/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 753ms/step - accuracy: 0.6581 - loss: 0.6214 - val_accuracy: 0.6631 - val_loss: 0.6178\n",
            "Epoch 54/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 790ms/step - accuracy: 0.6731 - loss: 0.6054 - val_accuracy: 0.6556 - val_loss: 0.6179\n",
            "Epoch 55/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 829ms/step - accuracy: 0.6524 - loss: 0.6203 - val_accuracy: 0.6513 - val_loss: 0.6263\n",
            "Epoch 56/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 867ms/step - accuracy: 0.6622 - loss: 0.6206 - val_accuracy: 0.6575 - val_loss: 0.6157\n",
            "Epoch 57/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 790ms/step - accuracy: 0.6613 - loss: 0.6144 - val_accuracy: 0.6556 - val_loss: 0.6196\n",
            "Epoch 58/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 775ms/step - accuracy: 0.6621 - loss: 0.6239 - val_accuracy: 0.6488 - val_loss: 0.6290\n",
            "Epoch 59/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 848ms/step - accuracy: 0.6654 - loss: 0.6155 - val_accuracy: 0.6563 - val_loss: 0.6138\n",
            "Epoch 60/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 777ms/step - accuracy: 0.6573 - loss: 0.6159 - val_accuracy: 0.6625 - val_loss: 0.6147\n",
            "Epoch 61/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 767ms/step - accuracy: 0.6621 - loss: 0.6216 - val_accuracy: 0.6544 - val_loss: 0.6179\n",
            "Epoch 62/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 829ms/step - accuracy: 0.6609 - loss: 0.6205 - val_accuracy: 0.6532 - val_loss: 0.6146\n",
            "Epoch 63/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 772ms/step - accuracy: 0.6559 - loss: 0.6171 - val_accuracy: 0.6394 - val_loss: 0.6232\n",
            "Epoch 64/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 806ms/step - accuracy: 0.6632 - loss: 0.6162 - val_accuracy: 0.6550 - val_loss: 0.6226\n",
            "Epoch 65/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 791ms/step - accuracy: 0.6736 - loss: 0.6085 - val_accuracy: 0.6163 - val_loss: 0.6350\n",
            "Epoch 66/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 823ms/step - accuracy: 0.6649 - loss: 0.6162 - val_accuracy: 0.6569 - val_loss: 0.6179\n",
            "Epoch 67/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 773ms/step - accuracy: 0.6707 - loss: 0.6138 - val_accuracy: 0.6532 - val_loss: 0.6168\n",
            "Epoch 68/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 860ms/step - accuracy: 0.6721 - loss: 0.6097 - val_accuracy: 0.6532 - val_loss: 0.6267\n",
            "Epoch 69/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 819ms/step - accuracy: 0.6580 - loss: 0.6206 - val_accuracy: 0.6556 - val_loss: 0.6180\n",
            "Epoch 70/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 791ms/step - accuracy: 0.6544 - loss: 0.6102 - val_accuracy: 0.6606 - val_loss: 0.6136\n",
            "Epoch 71/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 769ms/step - accuracy: 0.6735 - loss: 0.6034 - val_accuracy: 0.6563 - val_loss: 0.6109\n",
            "Epoch 72/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 767ms/step - accuracy: 0.6646 - loss: 0.6124 - val_accuracy: 0.6556 - val_loss: 0.6144\n",
            "Epoch 73/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 776ms/step - accuracy: 0.6732 - loss: 0.6043 - val_accuracy: 0.6538 - val_loss: 0.6156\n",
            "Epoch 74/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 780ms/step - accuracy: 0.6549 - loss: 0.6233 - val_accuracy: 0.6625 - val_loss: 0.6168\n",
            "Epoch 75/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 787ms/step - accuracy: 0.6626 - loss: 0.6129 - val_accuracy: 0.6563 - val_loss: 0.6202\n",
            "Epoch 76/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 752ms/step - accuracy: 0.6730 - loss: 0.6116 - val_accuracy: 0.6563 - val_loss: 0.6099\n",
            "Epoch 77/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 775ms/step - accuracy: 0.6667 - loss: 0.6173 - val_accuracy: 0.6550 - val_loss: 0.6089\n",
            "Epoch 78/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 774ms/step - accuracy: 0.6776 - loss: 0.6035 - val_accuracy: 0.6581 - val_loss: 0.6098\n",
            "Epoch 79/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 776ms/step - accuracy: 0.6608 - loss: 0.6127 - val_accuracy: 0.6613 - val_loss: 0.6193\n",
            "Epoch 80/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 795ms/step - accuracy: 0.6627 - loss: 0.6142 - val_accuracy: 0.6475 - val_loss: 0.6161\n",
            "Epoch 81/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 764ms/step - accuracy: 0.6657 - loss: 0.6118 - val_accuracy: 0.6600 - val_loss: 0.6136\n",
            "Epoch 82/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 778ms/step - accuracy: 0.6753 - loss: 0.6065 - val_accuracy: 0.6575 - val_loss: 0.6082\n",
            "Epoch 83/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 765ms/step - accuracy: 0.6770 - loss: 0.5978 - val_accuracy: 0.6600 - val_loss: 0.6174\n",
            "Epoch 84/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 779ms/step - accuracy: 0.6672 - loss: 0.6123 - val_accuracy: 0.6613 - val_loss: 0.6138\n",
            "Epoch 85/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 761ms/step - accuracy: 0.6709 - loss: 0.6097 - val_accuracy: 0.6525 - val_loss: 0.6260\n",
            "Epoch 86/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 775ms/step - accuracy: 0.6782 - loss: 0.6007 - val_accuracy: 0.6650 - val_loss: 0.6109\n",
            "Epoch 87/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 829ms/step - accuracy: 0.6746 - loss: 0.6068 - val_accuracy: 0.6288 - val_loss: 0.6327\n",
            "Epoch 88/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 784ms/step - accuracy: 0.6646 - loss: 0.6118 - val_accuracy: 0.6613 - val_loss: 0.6060\n",
            "Epoch 89/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 797ms/step - accuracy: 0.6705 - loss: 0.6051 - val_accuracy: 0.6719 - val_loss: 0.6087\n",
            "Epoch 90/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 767ms/step - accuracy: 0.6785 - loss: 0.6021 - val_accuracy: 0.6644 - val_loss: 0.6096\n",
            "Epoch 91/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 770ms/step - accuracy: 0.6677 - loss: 0.6122 - val_accuracy: 0.6631 - val_loss: 0.6122\n",
            "Epoch 92/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 776ms/step - accuracy: 0.6720 - loss: 0.6119 - val_accuracy: 0.6631 - val_loss: 0.6063\n",
            "Epoch 93/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 774ms/step - accuracy: 0.6668 - loss: 0.6006 - val_accuracy: 0.6631 - val_loss: 0.6067\n",
            "Epoch 94/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 782ms/step - accuracy: 0.6732 - loss: 0.6054 - val_accuracy: 0.6594 - val_loss: 0.6055\n",
            "Epoch 95/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 776ms/step - accuracy: 0.6585 - loss: 0.6146 - val_accuracy: 0.6631 - val_loss: 0.6044\n",
            "Epoch 96/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 778ms/step - accuracy: 0.6648 - loss: 0.6124 - val_accuracy: 0.6631 - val_loss: 0.6075\n",
            "Epoch 97/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 837ms/step - accuracy: 0.6726 - loss: 0.6057 - val_accuracy: 0.6594 - val_loss: 0.6200\n",
            "Epoch 98/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 780ms/step - accuracy: 0.6662 - loss: 0.6105 - val_accuracy: 0.6625 - val_loss: 0.6045\n",
            "Epoch 99/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 793ms/step - accuracy: 0.6745 - loss: 0.6113 - val_accuracy: 0.6563 - val_loss: 0.6059\n",
            "Epoch 100/100\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 857ms/step - accuracy: 0.6664 - loss: 0.6065 - val_accuracy: 0.6288 - val_loss: 0.6327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m448\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m4,640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m1,605,760\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,912,997\u001b[0m (18.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,912,997</span> (18.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,637,665\u001b[0m (6.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,637,665</span> (6.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,275,332\u001b[0m (12.49 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,275,332</span> (12.49 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k8T5wzXslljL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pLTdRrWLll9P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ytibfQUnnKl1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-2N5PxmFnbgr"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}