{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimrashaheen001/Programming_for_AI/blob/main/Lab_12_(tasksfile).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis (Text Classification)**\n",
        "*   **Downloading Datset from Kaggle to Google Colab**\n",
        "*   **Text Cleaning**\n",
        "*   **Text Preprocessing**\n",
        "*   **Feature Engineering**\n",
        "*   **ML Model**"
      ],
      "metadata": {
        "id": "QKxILf5ndoUD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmKnCfBodcue",
        "outputId": "9ca53436-a7cb-4d8b-daea-59732a4f9428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
            "License(s): other\n",
            "Downloading imdb-dataset-of-50k-movie-reviews.zip to /content\n",
            " 35% 9.00M/25.7M [00:00<00:00, 45.2MB/s]\n",
            "100% 25.7M/25.7M [00:00<00:00, 101MB/s] \n",
            "Archive:  imdb-dataset-of-50k-movie-reviews.zip\n",
            "  inflating: IMDB Dataset.csv        \n"
          ]
        }
      ],
      "source": [
        "#!/bin/bash\n",
        "!pip install kaggle\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Set up Kaggle API credentials\n",
        "#os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "#/content/kaggle.json\n",
        "# Make the Kaggle API key available to the environment\n",
        "with open('/content/kaggle.json') as f:\n",
        "    kaggle_json = json.load(f)\n",
        "    os.environ['KAGGLE_USERNAME'] = kaggle_json['username']\n",
        "    os.environ['KAGGLE_KEY'] = kaggle_json['key']\n",
        "\n",
        "#!/bin/bash\n",
        "!kaggle datasets download lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
        "\n",
        "!unzip imdb-dataset-of-50k-movie-reviews.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Preprocessing Libraries**"
      ],
      "metadata": {
        "id": "Opp1GMraebjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "stopwords.words('english')\n",
        "exclude = string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5-bcmcNee4l",
        "outputId": "e2a2d2f4-e94c-4a2b-b347-fd40ec50924b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading Data**"
      ],
      "metadata": {
        "id": "A4QQYCBbeonO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "df = temp_df.iloc[:30000]"
      ],
      "metadata": {
        "id": "IT9OMIfMe0jm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Cleaning & Preprocessing**"
      ],
      "metadata": {
        "id": "KkZ1tUgelQgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html_tags(text):\n",
        "    pattern = re.compile('<.*?>')\n",
        "    return pattern.sub(r'', text)\n",
        "\n",
        "def remove_url(text):\n",
        "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return pattern.sub(r'', text)\n",
        "\n",
        "#exclude = \"!.,?\"\n",
        "def remove_punc(text):\n",
        "    return text.translate(str.maketrans('', '', exclude))\n",
        "\n",
        "# Function to tokenize words\n",
        "def tokenize_words(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return [word for word in text if word.lower() not in stop_words]\n",
        "\n",
        "# Function to lemmatize words\n",
        "def lemmatize_words(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(word) for word in text]"
      ],
      "metadata": {
        "id": "1pKTCdM-e9ul"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].str.lower()\n",
        "\n",
        "df['review'] = df['review'].apply(remove_html_tags)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_url)\n",
        "\n",
        "df['review'] = df['review'].apply(remove_punc)\n",
        "\n",
        "df['review'] = df['review'].apply(tokenize_words)\n",
        "df['review'] = df['review'].apply(remove_stopwords)\n",
        "df['review'] = df['review'].apply(lemmatize_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMJGFEx7kbKF",
        "outputId": "c6b2eeb1-715f-4917-b8fa-3eaba5dc2422"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-e612315fa3ae>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].str.lower()\n",
            "<ipython-input-5-e612315fa3ae>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_html_tags)\n",
            "<ipython-input-5-e612315fa3ae>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_url)\n",
            "<ipython-input-5-e612315fa3ae>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_punc)\n",
            "<ipython-input-5-e612315fa3ae>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(tokenize_words)\n",
            "<ipython-input-5-e612315fa3ae>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(remove_stopwords)\n",
            "<ipython-input-5-e612315fa3ae>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['review'] = df['review'].apply(lemmatize_words)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "zV6bPViYl3_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Target Column Encoding**"
      ],
      "metadata": {
        "id": "JJozhru2MDY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#X = df.drop('sentiment', axis=1)\n",
        "X = df['review']\n",
        "Y = df['sentiment']\n",
        "\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(Y)\n",
        "\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuTETTE2Retv",
        "outputId": "0cb9cf65-1d7c-4624-9606-ef001378780c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        [one, reviewer, mentioned, watching, 1, oz, ep...\n",
            "1        [wonderful, little, production, filming, techn...\n",
            "2        [thought, wonderful, way, spend, time, hot, su...\n",
            "3        [basically, there, family, little, boy, jake, ...\n",
            "4        [petter, matteis, love, time, money, visually,...\n",
            "                               ...                        \n",
            "29995    [new, york, love, finally, make, shore, 10, sh...\n",
            "29996    [movie, make, wish, imdb, would, let, vote, ze...\n",
            "29997    [space, camp, unfortunate, luck, planned, arou...\n",
            "29998    [octavio, paz, mexican, poet, writer, diplomat...\n",
            "29999    [watched, 10, minute, movie, bewildered, watch...\n",
            "Name: review, Length: 30000, dtype: object\n",
            "0        positive\n",
            "1        positive\n",
            "2        positive\n",
            "3        negative\n",
            "4        positive\n",
            "           ...   \n",
            "29995    positive\n",
            "29996    negative\n",
            "29997    negative\n",
            "29998    positive\n",
            "29999    negative\n",
            "Name: sentiment, Length: 30000, dtype: object\n",
            "[1 1 1 ... 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bag of Words**"
      ],
      "metadata": {
        "id": "S7enK_qOl9Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "#print(X_train.head)\n",
        "\n",
        "X_train = X_train.apply(lambda x: ' '.join(x))\n",
        "X_test = X_test.apply(lambda x: ' '.join(x))\n",
        "#print(X_train)\n",
        "#print(X_test)\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data and transform it\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_bow.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_bow.shape}\")\n",
        "\n",
        "# Applying Random Forest Classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_bow,y_train)\n",
        "y_pred = rf.predict(X_test_bow)\n",
        "#accuracy_score(y_test,y_pred)\n",
        "\n",
        "print (accuracy_score(y_test,y_pred))\n",
        "print (confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu52GS7sSEbM",
        "outputId": "9f104ce0-726b-480a-a837-d25cb12887a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24000,)\n",
            "Shape of X_train_bow: (24000, 130918)\n",
            "Shape of X_test_bow: (6000, 130918)\n",
            "0.8533333333333334\n",
            "[[2604  425]\n",
            " [ 455 2516]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**n-gram (2-gram)**"
      ],
      "metadata": {
        "id": "J1sjksiJMUIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(ngram_range=(2,2))\n",
        "\n",
        "X_train_n_gram = cv.fit_transform(X_train)\n",
        "X_test_n_gram = cv.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_n_gram.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_n_gram.shape}\")\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_n_gram,y_train)\n",
        "y_pred = rf.predict(X_test_n_gram)\n",
        "\n",
        "print (accuracy_score(y_test,y_pred))\n",
        "print (confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m0KGuBSNatZ",
        "outputId": "75032796-a79d-44ab-dcec-91c72e1de1c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_bow: (24000, 1702353)\n",
            "Shape of X_test_bow: (6000, 1702353)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF/IDF**"
      ],
      "metadata": {
        "id": "4QsY7r2INm7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Output the shapes of the resulting Bag of Words matrices\n",
        "print(f\"Shape of X_train_bow: {X_train_tfidf.shape}\")\n",
        "print(f\"Shape of X_test_bow: {X_test_tfidf.shape}\")\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_tfidf,y_train)\n",
        "y_pred = rf.predict(X_test_tfidf)\n",
        "\n",
        "print (accuracy_score(y_test,y_pred))\n",
        "print (confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "id": "WQNLOLLyNr2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task:**\n",
        "*   **Add a Python Function for Word-based Tokenization for each of the IMDB reviews data.**\n",
        "*   **After tokenization, add a Python Function to remove Stop Words from the IMDB reviews data.**\n",
        "*   **After Stopword Removal, add a Python Function to perform Lemmitization over IMDB Reviews data.**\n",
        "\n",
        "**After applying the above mentioned data preprocessing steps, again run this code and analyse the performance of the ML models for text classification of IMDB Reviews.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xbqQjfUg4PG3"
      }
    }
  ]
}